{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a25ad9-80f0-4051-a126-f70fe9805596",
   "metadata": {},
   "source": [
    "Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e5e8d-b226-48f9-b7e7-b02a63d078ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio \n",
    "!pip3 install transformers\n",
    "!pip3 install sklearn\n",
    "!pip3 install pandas\n",
    "!pip3 install numpy\n",
    "!pip3 install tabulate\n",
    "!pip3 install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0af34bd-6724-4487-ab2f-24e426a82d51",
   "metadata": {},
   "source": [
    "Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953f229d-1101-4a8f-ba6d-cab34c72a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a62c2eb-e6e0-4ea5-b87a-3a45788cf657",
   "metadata": {
    "tags": []
   },
   "source": [
    "Code for RoBERTa Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f567a5-e665-4b73-bf33-19872e9a1df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('IMDB_Reviews_Top_250_preprocessed_without_stopwords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa43e165-cc83-4487-a0e7-83efec5a6d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1507b2fa-f141-44e8-a5ec-d306b6d1d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the threshold for binary conversion\n",
    "threshold = 7.0\n",
    "\n",
    "# Convert the 'Rating' column to a binary variable\n",
    "data['Binary Rating'] = data['Rating'].apply(lambda x: 1 if x >= threshold else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd4c247-0020-4d83-9aa6-ae3b9278de8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract reviews texts and ratings into arrays\n",
    "reviews = data['Review Text'].values\n",
    "labels = data['Binary Rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fa5d5d-f4b9-4765-858b-5d91d0445b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shouldn't be necessary but just to be safe\n",
    "for review in reviews:\n",
    "    str(review)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb3c412-4156-448c-b2b7-736396bb4fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count the number of rows with label 1\n",
    "num_label_1 = data[data['Binary Rating'] == 1]['Binary Rating'].count()\n",
    "\n",
    "# Count the number of rows with label 0\n",
    "num_label_0 = data[data['Binary Rating'] == 0]['Binary Rating'].count()\n",
    "\n",
    "print(f\"Number of rows with Binary Rating 1: {num_label_1}\")\n",
    "print(f\"Number of rows with Binary Rating 0: {num_label_0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99b0ec8-77ad-4d09-a996-67b3dd6bdf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fb5101-24b0-43a1-9d35-deca069ac7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02ff815-0bf4-4d69-9d64-b43ce7cf94d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load RoBERTa tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bcc2a9-ad54-4f2f-b7c3-40ec82850fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing tokens and token Ids for a random sentence\n",
    "def print_rand_sentence():\n",
    "    index = random.randint(0, len(reviews)-1) #random index in texts list\n",
    "    table = np.array([tokenizer.tokenize(reviews[index]), \n",
    "                    tokenizer.convert_tokens_to_ids(tokenizer.tokenize(reviews[index]))]).T #tokenize random text in texts list\n",
    "    print(tabulate(table,\n",
    "                 headers = ['Tokens', 'Token IDs'],\n",
    "                 tablefmt = 'fancy_grid'))  #print in table format\n",
    "\n",
    "print_rand_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffecf431-1310-4ae5-a2cd-70023faa17ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find max sequensce lenght\n",
    "\n",
    "MAX_LEN = 0\n",
    "for review in reviews:\n",
    "    tokenized = tokenizer(review,return_tensors='pt',add_special_tokens=True)\n",
    "    MAX_LEN = max(MAX_LEN, tokenized['input_ids'].size()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ea996f-22ca-48e2-b0cb-45df50159018",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa999cad-9320-4681-88cd-5646c1b836f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode texts then extract token ids, attention masks and labels in torch tensor format.\n",
    "token_id = []\n",
    "attention_masks = []\n",
    "\n",
    "def preprocessing(input_text, tokenizer):\n",
    "    return tokenizer.encode_plus(                    #returns dictionary with token ids, attention masks and token type ids\n",
    "                        input_text,\n",
    "                        max_length = 512,            \n",
    "                        padding = 'max_length',    #padding tokens to be of the same size\n",
    "                        truncation=True,           # Truncate the text if it exceeds 512 tokens\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt'        #torch tensor format\n",
    "                   )\n",
    "\n",
    "\n",
    "for sample in reviews:\n",
    "    encoding_dict = preprocessing(sample, tokenizer)\n",
    "    token_id.append(encoding_dict['input_ids']) \n",
    "    attention_masks.append(encoding_dict['attention_mask'])\n",
    "\n",
    "#concatinating the tesnors in a single dimension\n",
    "token_id = torch.cat(token_id, dim = 0)\n",
    "attention_masks = torch.cat(attention_masks, dim = 0)\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf5294-fbe5-46fd-8ae0-344aaf6eec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25244648-ac7f-4ec4-8822-eccece150543",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941b4676-0786-49e3-8d38-54549dce55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b68946-d124-4399-881a-f4ca7883260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rand_sentence_encoding():\n",
    "    index = random.randint(0, len(reviews) - 1)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(token_id[index].numpy().tolist())  # Convert token_ids to a list of strings\n",
    "    token_ids = token_id[index].numpy()\n",
    "    attention = attention_masks[index].numpy()\n",
    "\n",
    "    table = np.array([tokens, token_ids, attention]).T\n",
    "    print(tabulate(table, headers=['Tokens', 'Token IDs', 'Attention Mask'], tablefmt='fancy_grid'))\n",
    "\n",
    "print_rand_sentence_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a80ee44-ec0f-47a2-bde4-de730639d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in training and validation sets\n",
    "\n",
    "val_ratio = 0.2 \n",
    "batch_size = 16\n",
    "\n",
    "# Indices of the train and validation splits stratified by labels\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(labels)),\n",
    "    test_size = val_ratio,\n",
    "    shuffle = True,\n",
    "    stratify = labels)\n",
    "\n",
    "# Train and validation sets\n",
    "train_set = TensorDataset(token_id[train_idx], \n",
    "                          attention_masks[train_idx], \n",
    "                          labels[train_idx])\n",
    "\n",
    "val_set = TensorDataset(token_id[val_idx], \n",
    "                        attention_masks[val_idx], \n",
    "                        labels[val_idx])\n",
    "\n",
    "# DataLoaders\n",
    "train_dataloader = DataLoader(\n",
    "            train_set,\n",
    "            sampler = RandomSampler(train_set),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_set,\n",
    "            sampler = SequentialSampler(val_set),\n",
    "            batch_size = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee0b0fd-c6b4-44a7-92e2-99c5ebc0961e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load RoBERTa model as a RobertaForSequenceClassification model\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "                model.parameters(),\n",
    "                lr=3e-5,     # You can also try 3e-5, 2e-5\n",
    "                eps=1e-8     # AdamW's epsilon value. Probably optimal.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a425528-224a-40f1-a5cd-c35d8196a4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device and move the model to it\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26043b47-cc1d-40de-9a76-3c0ac30da505",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "debug_interval = 60  # Print a debug message every 60 seconds\n",
    "\n",
    "# Define variables for early stopping\n",
    "patience = 3\n",
    "min_delta = 0.001\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "\n",
    "start_time = time.time()  # Record the start time\n",
    "\n",
    "for epoch in trange(epochs, desc='Epoch'):\n",
    "    # Set model to training mode for training loop\n",
    "    model.train()\n",
    "\n",
    "    # Tracking variables\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        train_output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        # Backward pass\n",
    "        train_output.loss.backward()\n",
    "        optimizer.step()\n",
    "        # Update tracking variables\n",
    "        tr_loss += train_output.loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "        # Check if five seconds have passed, and print a debug message\n",
    "        if time.time() - start_time > debug_interval:\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Step {step + 1}/{len(train_dataloader)}, \"\n",
    "                  f\"Train Loss: {tr_loss / nb_tr_steps:.4f}\")\n",
    "            start_time = time.time()  # Reset the start time for the next 60 seconds\n",
    "\n",
    "    # After the training loop, save the model checkpoint for each epoch\n",
    "    torch.save(model.state_dict(), f'model_checkpoint_epoch_RoBERTa_Classifier_{epoch + 1}.pt')\n",
    "    \n",
    "    # Set model to evaluation mode for validation loop\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialise metrics \n",
    "    val_loss = 0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            # Forward pass\n",
    "            eval_output = model(b_input_ids, \n",
    "                              token_type_ids=None, \n",
    "                              attention_mask=b_input_mask, \n",
    "                              labels=b_labels)\n",
    "        logits = eval_output.logits\n",
    "        eval_loss = eval_output.loss\n",
    "        val_loss += eval_loss.item()\n",
    "\n",
    "        # Calculate validation metrics\n",
    "        preds = torch.argmax(logits, dim=1).cpu().detach().numpy()\n",
    "        label_ids = b_labels.cpu().detach().numpy()\n",
    "        val_preds.extend(preds)\n",
    "        val_labels.extend(label_ids)\n",
    "\n",
    "    # Calculate average metrics over all batches\n",
    "    avg_val_loss = val_loss / len(validation_dataloader)\n",
    "    avg_val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "    avg_val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
    "    print('\\n\\t - Validation loss: {:.4f}'.format(avg_val_loss))\n",
    "    print('\\n\\t - Validation accuracy: {:.4f}'.format(avg_val_accuracy))\n",
    "    print('\\n\\t - Validation F1 score: {:.4f}'.format(avg_val_f1))\n",
    "\n",
    "    # Check if validation loss improved\n",
    "    if avg_val_loss < best_val_loss - min_delta * best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter == patience:\n",
    "            print(\"Validation loss did not improve for {} epochs. Early stopping...\".format(patience))\n",
    "            break\n",
    "\n",
    "# After the training loop finishes, close the results file\n",
    "results_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
