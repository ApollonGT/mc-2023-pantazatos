{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c02812a-171c-4163-9943-c8e967615e12",
   "metadata": {},
   "source": [
    "Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15052994-cdad-481e-bc3e-d6f38590cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio \n",
    "!pip3 install transformers\n",
    "!pip3 install sklearn\n",
    "!pip3 install pandas\n",
    "!pip3 install numpy\n",
    "!pip3 install tabulate\n",
    "!pip3 install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27be88f8-aca3-46b4-be63-c6e53d964e92",
   "metadata": {},
   "source": [
    "Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af2e23-c26d-416a-9a37-f88ea95c4304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AutoTokenizer, AutoModel, ElectraForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd132020-4111-47aa-b6e4-10618960b245",
   "metadata": {},
   "source": [
    "Code for ELECTRA Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d4c2a-3542-4ec8-b0ea-33d93a41f7df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('IMDB_Reviews_Top_250_preprocessed_without_stopwords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f4002b-3992-4d98-9f4c-932585d0b838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b5f4cc-112f-4f80-bae7-1014c05352d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the threshold for binary conversion\n",
    "threshold = 7.0\n",
    "\n",
    "# Convert the 'Rating' column to a binary variable\n",
    "data['Binary Rating'] = data['Rating'].apply(lambda x: 1 if x >= threshold else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5712b494-13c5-46fe-9e52-25b991844038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract reviews texts and ratings into arrays\n",
    "reviews = data['Review Text'].values\n",
    "labels = data['Binary Rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008141ab-fe9d-47b4-959c-effb70c29e47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Shouldn't be necessary but just to be safe\n",
    "for review in reviews:\n",
    "    str(review)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e17ac5f-81f0-43fb-bcef-1c14d57777b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count the number of rows with label 1\n",
    "num_label_1 = data[data['Binary Rating'] == 1]['Binary Rating'].count()\n",
    "\n",
    "# Count the number of rows with label 0\n",
    "num_label_0 = data[data['Binary Rating'] == 0]['Binary Rating'].count()\n",
    "\n",
    "print(f\"Number of rows with Binary Rating 1: {num_label_1}\")\n",
    "print(f\"Number of rows with Binary Rating 0: {num_label_0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d03d2b-959b-4ea9-8607-b5edb8196158",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70622193-a55c-445a-9399-2e902de79c62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4594cee9-f4df-437f-836d-b6b2a7760b48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load ELECTRA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/electra-small-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f128c42-ee05-4539-b0e4-1dc5bd608b82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing tokens and token Ids for a random sentence\n",
    "def print_rand_sentence():\n",
    "    index = random.randint(0, len(reviews)-1) #random index in texts list\n",
    "    table = np.array([tokenizer.tokenize(reviews[index]), \n",
    "                    tokenizer.convert_tokens_to_ids(tokenizer.tokenize(reviews[index]))]).T #tokenize random text in texts list\n",
    "    print(tabulate(table,\n",
    "                 headers = ['Tokens', 'Token IDs'],\n",
    "                 tablefmt = 'fancy_grid'))  #print in table format\n",
    "\n",
    "print_rand_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d3f906-abab-4326-bcb9-f596bb356cde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find max sequensce lenght\n",
    "\n",
    "MAX_LEN = 0\n",
    "for review in reviews:\n",
    "    tokenized = tokenizer(review,return_tensors='pt',add_special_tokens=True)\n",
    "    MAX_LEN = max(MAX_LEN, tokenized['input_ids'].size()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d087f2f-920f-4921-8107-fcd54047f7f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74fd1c7-bec4-4ba8-bcef-db01ef8932f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize and encode texts then extract token ids, attention masks and labels in torch tensor format.\n",
    "token_id = []\n",
    "attention_masks = []\n",
    "\n",
    "def preprocessing(input_text, tokenizer):\n",
    "    return tokenizer.encode_plus(                    #returns dictionary with token ids, attention masks and token type ids\n",
    "                        input_text,\n",
    "                        max_length = 512,\n",
    "                        add_special_tokens = True,\n",
    "                        padding = 'max_length',    #padding tokens to be of the same size\n",
    "                        truncation=True,           # Truncate the text if it exceeds 512 tokens\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt'        #torch tensor format\n",
    "                   )\n",
    "\n",
    "\n",
    "for sample in reviews:\n",
    "    encoding_dict = preprocessing(sample, tokenizer)\n",
    "    token_id.append(encoding_dict['input_ids']) \n",
    "    attention_masks.append(encoding_dict['attention_mask'])\n",
    "\n",
    "#concatinating the tesnors in a single dimension\n",
    "token_id = torch.cat(token_id, dim = 0)\n",
    "attention_masks = torch.cat(attention_masks, dim = 0)\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e934ca-acbd-4922-9f3c-8fc89df8ebb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a609a1-2e91-4ed3-b000-3144b26c8700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ad912f-1d91-4ca4-b26d-9b7a5abc2ad2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57172a8c-c283-4938-8351-eeddc91e1ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print ids and masks for a random sentence\n",
    "def print_rand_sentence_encoding():\n",
    "    index = random.randint(0, len(review) - 1)\n",
    "    tokens = tokenizer.tokenize(tokenizer.decode(token_id[index]))\n",
    "    token_ids = [i.numpy() for i in token_id[index]]\n",
    "    attention = [i.numpy() for i in attention_masks[index]]\n",
    "    table = np.array([tokens, token_ids, attention]).T\n",
    "    print(tabulate(table, \n",
    "                 headers = ['Tokens', 'Token IDs', 'Attention Mask'],\n",
    "                 tablefmt = 'fancy_grid'))\n",
    "\n",
    "print_rand_sentence_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596c2bbe-6700-46f2-bf38-ec645d35ad6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split data in training and validation sets\n",
    "\n",
    "val_ratio = 0.2 \n",
    "batch_size = 16\n",
    "\n",
    "# Indices of the train and validation splits stratified by labels\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(labels)),\n",
    "    test_size = val_ratio,\n",
    "    shuffle = True,\n",
    "    stratify = labels)\n",
    "\n",
    "# Train and validation sets\n",
    "train_set = TensorDataset(token_id[train_idx], \n",
    "                          attention_masks[train_idx], \n",
    "                          labels[train_idx])\n",
    "\n",
    "val_set = TensorDataset(token_id[val_idx], \n",
    "                        attention_masks[val_idx], \n",
    "                        labels[val_idx])\n",
    "\n",
    "# DataLoaders\n",
    "train_dataloader = DataLoader(\n",
    "            train_set,\n",
    "            sampler = RandomSampler(train_set),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_set,\n",
    "            sampler = SequentialSampler(val_set),\n",
    "            batch_size = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e88b4b6-629a-45a6-ad10-3c662149f7ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ElectraForSequenceClassification.from_pretrained(\n",
    "    \"google/electra-small-discriminator\",\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "                model.parameters(),\n",
    "                lr=3e-5,     # You can also try 3e-5, 2e-5\n",
    "                eps=1e-8     # AdamW's epsilon value. Probably optimal.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e7768-f990-49b3-a867-a84397ef527b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define device and move the model to it\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b44e462-e770-4c91-bbf8-5f1975408d68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "debug_interval = 60  # Print a debug message every 60 seconds\n",
    "\n",
    "# Define variables for early stopping\n",
    "patience = 3\n",
    "min_delta = 0.001\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "\n",
    "start_time = time.time()  # Record the start time\n",
    "\n",
    "for epoch in trange(epochs, desc='Epoch'):\n",
    "    # Set model to training mode for training loop\n",
    "    model.train()\n",
    "\n",
    "    # Tracking variables\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        train_output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        # Backward pass\n",
    "        train_output.loss.backward()\n",
    "        optimizer.step()\n",
    "        # Update tracking variables\n",
    "        tr_loss += train_output.loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "        # Check if five seconds have passed, and print a debug message\n",
    "        if time.time() - start_time > debug_interval:\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Step {step + 1}/{len(train_dataloader)}, \"\n",
    "                  f\"Train Loss: {tr_loss / nb_tr_steps:.4f}\")\n",
    "            start_time = time.time()  # Reset the start time for the next 60 seconds\n",
    "\n",
    "    # After the training loop, save the model checkpoint for each epoch\n",
    "    torch.save(model.state_dict(), f'model_checkpoint_epoch_ELECTRA_Classifier_{epoch + 1}.pt')\n",
    "    \n",
    "    # Set model to evaluation mode for validation loop\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialise metrics \n",
    "    val_loss = 0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            # Forward pass\n",
    "            eval_output = model(b_input_ids, \n",
    "                              token_type_ids=None, \n",
    "                              attention_mask=b_input_mask, \n",
    "                              labels=b_labels)\n",
    "        logits = eval_output.logits\n",
    "        eval_loss = eval_output.loss\n",
    "        val_loss += eval_loss.item()\n",
    "\n",
    "        # Calculate validation metrics\n",
    "        preds = torch.argmax(logits, dim=1).cpu().detach().numpy()\n",
    "        label_ids = b_labels.cpu().detach().numpy()\n",
    "        val_preds.extend(preds)\n",
    "        val_labels.extend(label_ids)\n",
    "\n",
    "    # Calculate average metrics over all batches\n",
    "    avg_val_loss = val_loss / len(validation_dataloader)\n",
    "    avg_val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "    avg_val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
    "    print('\\n\\t - Validation loss: {:.4f}'.format(avg_val_loss))\n",
    "    print('\\n\\t - Validation accuracy: {:.4f}'.format(avg_val_accuracy))\n",
    "    print('\\n\\t - Validation F1 score: {:.4f}'.format(avg_val_f1))\n",
    "\n",
    "    # Check if validation loss improved\n",
    "    if avg_val_loss < best_val_loss - min_delta * best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter == patience:\n",
    "            print(\"Validation loss did not improve for {} epochs. Early stopping...\".format(patience))\n",
    "            break\n",
    "\n",
    "# After the training loop finishes, close the results file\n",
    "results_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
