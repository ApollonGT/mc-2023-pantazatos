{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2cd8d9d-70e8-4cd2-b988-6d792d18c567",
   "metadata": {},
   "source": [
    "Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea86fe-7e9d-496e-8e09-4e369024f34f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install transformers\n",
    "!pip install sklearn\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install tabulate\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc51fc2-de5c-40a8-b357-654968e485ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AutoTokenizer, AutoModel, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeabbdf-bd2e-4283-8296-dce4291c9ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('IMDB_Reviews_Top_250_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb6a427-a5da-4af6-b85d-b7ccfe4804bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a31fc2c-b8d3-409b-9fb0-d1451d45af04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the threshold for binary conversion\n",
    "threshold = 7.0\n",
    "\n",
    "# Convert the 'Rating' column to a binary variable\n",
    "data['Binary Rating'] = data['Rating'].apply(lambda x: 1 if x >= threshold else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bed798-bb1b-4366-8a92-db7d66ee2f58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract reviews texts and ratings into arrays\n",
    "reviews = data['Review Text'].values\n",
    "labels = data['Binary Rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd58c08-f221-45e0-a62f-f0a583c3e12e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Shouldn't be necessary but just to be safe\n",
    "for review in reviews:\n",
    "    str(review)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14074b31-8014-4f83-9aef-70c94a7b568f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count the number of rows with label 1\n",
    "num_label_1 = data[data['Binary Rating'] == 1]['Binary Rating'].count()\n",
    "\n",
    "# Count the number of rows with label 0\n",
    "num_label_0 = data[data['Binary Rating'] == 0]['Binary Rating'].count()\n",
    "\n",
    "print(f\"Number of rows with Binary Rating 1: {num_label_1}\")\n",
    "print(f\"Number of rows with Binary Rating 0: {num_label_0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8c7ea8-4203-4f9c-865f-032736e20d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e08767-5f23-4fbf-a42d-5be0317e2ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be4c7bc-1e18-4aa3-a69e-caef9479f2cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b27cea5-d480-4c33-ba77-6f4e9944ac69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing tokens and token Ids for a random sentence\n",
    "def print_rand_sentence():\n",
    "    index = random.randint(0, len(reviews)-1) #random index in texts list\n",
    "    table = np.array([tokenizer.tokenize(reviews[index]), \n",
    "                    tokenizer.convert_tokens_to_ids(tokenizer.tokenize(reviews[index]))]).T #tokenize random text in texts list\n",
    "    print(tabulate(table,\n",
    "                 headers = ['Tokens', 'Token IDs'],\n",
    "                 tablefmt = 'fancy_grid'))  #print in table format\n",
    "\n",
    "print_rand_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb21b6-0c6b-46f9-a456-fc04f36f7530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find max sequensce length\n",
    "\n",
    "MAX_LEN = 0\n",
    "for review in reviews:\n",
    "    tokenized = tokenizer(review,return_tensors='pt',add_special_tokens=True)\n",
    "    MAX_LEN = max(MAX_LEN, tokenized['input_ids'].size()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6f696d-efe3-4ec8-98c6-fe72ed6aa542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aa876f-0006-4de1-8ff3-06bad690fb84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize and encode texts then extract token ids, attention masks and labels in torch tensor format.\n",
    "token_id = []\n",
    "attention_masks = []\n",
    "\n",
    "def preprocessing(input_text, tokenizer):\n",
    "    return tokenizer.encode_plus(                    #returns dictionary with token ids, attention masks and token type ids\n",
    "                        input_text,\n",
    "                        add_special_tokens = True,   #[CLS], [SEP] tokens required by BERT\n",
    "                        max_length = 512,            #calculated above\n",
    "                        padding='max_length',    #padding tokens to be of the same size\n",
    "                        truncation=True,           # Truncate the text if it exceeds 512 tokens\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt'        #torch tensor format\n",
    "                   )\n",
    "\n",
    "\n",
    "for sample in reviews:\n",
    "    encoding_dict = preprocessing(sample, tokenizer)\n",
    "    token_id.append(encoding_dict['input_ids']) \n",
    "    attention_masks.append(encoding_dict['attention_mask'])\n",
    "\n",
    "\n",
    "token_id = torch.cat(token_id, dim = 0) #concatinating the tesnors in a single dimension\n",
    "attention_masks = torch.cat(attention_masks, dim = 0)\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05319ea-a6ea-4675-9c9c-7a4d66a6a037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a85dac7-d78a-4210-97f1-a0d417937d56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca16be-a2ce-4535-8275-4871295d5015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7491262d-61f8-45cd-a875-6f260d39b627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print ids and masks for a random sentence\n",
    "def print_rand_sentence_encoding():\n",
    "    index = random.randint(0, len(review) - 1)\n",
    "    tokens = tokenizer.tokenize(tokenizer.decode(token_id[index]))\n",
    "    token_ids = [i.numpy() for i in token_id[index]]\n",
    "    attention = [i.numpy() for i in attention_masks[index]]\n",
    "    table = np.array([tokens, token_ids, attention]).T\n",
    "    print(tabulate(table, \n",
    "                 headers = ['Tokens', 'Token IDs', 'Attention Mask'],\n",
    "                 tablefmt = 'fancy_grid'))\n",
    "\n",
    "print_rand_sentence_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b30ba6-e92a-4333-baa7-1d18ed16b375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split data in training and validation sets\n",
    "\n",
    "val_ratio = 0.2 \n",
    "batch_size = 16\n",
    "\n",
    "# Indices of the train and validation splits stratified by labels\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(labels)),\n",
    "    test_size = val_ratio,\n",
    "    shuffle = True,\n",
    "    stratify = labels)\n",
    "\n",
    "# Train and validation sets\n",
    "train_set = TensorDataset(token_id[train_idx], \n",
    "                          attention_masks[train_idx], \n",
    "                          labels[train_idx])\n",
    "\n",
    "val_set = TensorDataset(token_id[val_idx], \n",
    "                        attention_masks[val_idx], \n",
    "                        labels[val_idx])\n",
    "\n",
    "# DataLoaders\n",
    "train_dataloader = DataLoader(\n",
    "            train_set,\n",
    "            sampler = RandomSampler(train_set),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_set,\n",
    "            sampler = SequentialSampler(val_set),\n",
    "            batch_size = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb785bde-425f-4f31-a17c-d5e04b8bf39f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load BERT model as a BertForSequenceClassification model\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-cased\",\n",
    "    num_labels = 2,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "                model.parameters(), \n",
    "                lr = 3e-5,  # can also try 3e-5, 2e-5\n",
    "                eps = 1e-08 # AdamW's epsilon value. Probably optimal.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e046e5-78c7-4bdc-958d-0e22963d9c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define device and move the model to it\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2b620-282d-402c-b146-74894c8ce9c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "debug_interval = 60  # Print a debug message every 5 seconds\n",
    "\n",
    "# Define variables for early stopping\n",
    "patience = 3\n",
    "min_delta = 0.001\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "\n",
    "start_time = time.time()  # Record the start time\n",
    "\n",
    "for epoch in trange(epochs, desc='Epoch'):\n",
    "    # Set model to training mode for training loop\n",
    "    model.train()\n",
    "\n",
    "    # Tracking variables\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        train_output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        # Backward pass\n",
    "        train_output.loss.backward()\n",
    "        optimizer.step()\n",
    "        # Update tracking variables\n",
    "        tr_loss += train_output.loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "        # Check if five seconds have passed, and print a debug message\n",
    "        if time.time() - start_time > debug_interval:\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Step {step + 1}/{len(train_dataloader)}, \"\n",
    "                  f\"Train Loss: {tr_loss / nb_tr_steps:.4f}\")\n",
    "            start_time = time.time()  # Reset the start time for the next 5 seconds\n",
    "\n",
    "    # Set model to evaluation mode for validation loop\n",
    "    model.eval()\n",
    "        \n",
    "    # Set model to evaluation mode for validation loop\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialise metrics \n",
    "    val_loss = 0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            # Forward pass\n",
    "            eval_output = model(b_input_ids, \n",
    "                              token_type_ids=None, \n",
    "                              attention_mask=b_input_mask, \n",
    "                              labels=b_labels)\n",
    "        logits = eval_output.logits\n",
    "        eval_loss = eval_output.loss\n",
    "        val_loss += eval_loss.item()\n",
    "\n",
    "        # Calculate validation metrics\n",
    "        preds = torch.argmax(logits, dim=1).cpu().detach().numpy()\n",
    "        label_ids = b_labels.cpu().detach().numpy()\n",
    "        val_preds.extend(preds)\n",
    "        val_labels.extend(label_ids)\n",
    "\n",
    "    # Calculate average metrics over all batches\n",
    "    avg_val_loss = val_loss / len(validation_dataloader)\n",
    "    avg_val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "    avg_val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
    "    print('\\n\\t - Validation loss: {:.4f}'.format(avg_val_loss))\n",
    "    print('\\n\\t - Validation accuracy: {:.4f}'.format(avg_val_accuracy))\n",
    "    print('\\n\\t - Validation F1 score: {:.4f}'.format(avg_val_f1))\n",
    "\n",
    "    # Check if validation loss improved\n",
    "    if avg_val_loss < best_val_loss - min_delta * best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        counter = 0\n",
    "        # Save the model\n",
    "        torch.save(model.state_dict(), 'best_model_bert.pt')\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter == patience:\n",
    "            print(\"Validation loss did not improve for {} epochs. Early stopping...\".format(patience))\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
